{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nx5YYnIJ3w3q"
   },
   "source": [
    "**Aim:**\n",
    "\n",
    "In this kernel, we aim to use the final model, designed in kernel main3, to test it on the hold out test set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3JdPG-do3w3t"
   },
   "source": [
    "### Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "executionInfo": {
     "elapsed": 2395,
     "status": "ok",
     "timestamp": 1684339753651,
     "user": {
      "displayName": "Radial Mimic",
      "userId": "13785279993639843263"
     },
     "user_tz": -210
    },
    "id": "TkRa2T_N3w3u"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<frozen importlib._bootstrap>:228: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tqdm\n",
    "import pickle\n",
    "import sklearn\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import precision_recall_curve\n",
    "import matplotlib.pyplot as plt\n",
    "from imblearn import pipeline\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier, EasyEnsembleClassifier\n",
    "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, roc_auc_score, confusion_matrix\n",
    "\n",
    "from FeatureSelection import FeatureSelector\n",
    "from Metrics import MetricsCal\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OO4Z3pDv4YWx"
   },
   "source": [
    "### Loading the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "executionInfo": {
     "elapsed": 1425,
     "status": "ok",
     "timestamp": 1684350632071,
     "user": {
      "displayName": "Radial Mimic",
      "userId": "13785279993639843263"
     },
     "user_tz": -210
    },
    "id": "8zNeRJQf3w3x"
   },
   "outputs": [],
   "source": [
    "FeatureDir = \"../Data/ExtractedFeatures/Pearson/AVI_P_features_Thr0.875.csv\"\n",
    "with open(\"../Data/Test_IDs/TestID.pickle\", \"rb\") as file:\n",
    "    Test_IDs = pickle.load(file)\n",
    "\n",
    "# Reading the Feature matrix\n",
    "df = pd.read_csv(FeatureDir)\n",
    "\n",
    "\n",
    "df_train = df[~df[\"ScanDir ID\"].isin(Test_IDs)]\n",
    "df_test = df[df[\"ScanDir ID\"].isin(Test_IDs)]\n",
    "\n",
    "# preparing the feature set and labels\n",
    "X_train, y_train = df_train.iloc[:, 1:-5], np.array(df_train.loc[:, \"DX\"])\n",
    "X_test, y_test = df_test.iloc[:, 1:-5], np.array(df_test.loc[:, \"DX\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLZqBFAq3w3x"
   },
   "source": [
    "### Feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "executionInfo": {
     "elapsed": 115594,
     "status": "ok",
     "timestamp": 1684350747661,
     "user": {
      "displayName": "Radial Mimic",
      "userId": "13785279993639843263"
     },
     "user_tz": -210
    },
    "id": "XI0cql7y3w3y"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "35\n"
     ]
    }
   ],
   "source": [
    "random_state, n_split = 0, 7\n",
    "ImpFeatures = FeatureSelector(X_train, y_train, random_state, n_split, 1000, 45, 2)\n",
    "X_train = X_train.loc[:, ImpFeatures]\n",
    "X_test = X_test.loc[:, ImpFeatures]\n",
    "\n",
    "print(len(ImpFeatures))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "ImpFeatures.append(\"DX\")\n",
    "data2 = df.loc[:, ImpFeatures]\n",
    "data2.to_csv(\"PearsonData2.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bh9rrgFs3w3z"
   },
   "source": [
    "Modeling pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 100080,
     "status": "ok",
     "timestamp": 1684348486744,
     "user": {
      "displayName": "Radial Mimic",
      "userId": "13785279993639843263"
     },
     "user_tz": -210
    },
    "id": "hj3fvnsL3w3z",
    "outputId": "201353d4-c534-4547-ea06-5f72c8e4a0a5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 28/50 [02:15<01:33,  4.23s/it]"
     ]
    }
   ],
   "source": [
    "# Function to load data from a pickle file\n",
    "def load_data(path):\n",
    "    with open(path, \"rb\") as file:\n",
    "        return pickle.load(file)\n",
    "\n",
    "# Function to normalize data using StandardScaler\n",
    "def normalize_data(X_train, X_test):\n",
    "    scaler = StandardScaler()\n",
    "    X_train_normalized = scaler.fit_transform(X_train)\n",
    "    X_test_normalized = scaler.transform(X_test)\n",
    "    return X_train_normalized, X_test_normalized\n",
    "\n",
    "# Function to build a classifier based on the given name\n",
    "def build_classifier(classifier_name):\n",
    "    if classifier_name == \"XGB\":\n",
    "        return XGBClassifier(\n",
    "            max_depth=3,\n",
    "            min_child_weight=1,\n",
    "            subsample=0.5,\n",
    "            learning_rate=0.8,\n",
    "            n_estimators=150,\n",
    "            scale_pos_weight=100\n",
    "        )\n",
    "    elif classifier_name == \"BRF\":\n",
    "        return BalancedRandomForestClassifier(\n",
    "            criterion='gini', \n",
    "            max_depth=10, \n",
    "            max_features='sqrt', \n",
    "            min_samples_split=2, \n",
    "            n_estimators=150\n",
    "        )\n",
    "    elif classifier_name == \"EEC\":\n",
    "        return EasyEnsembleClassifier(n_estimators=10)\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid classifier name: {classifier_name}\")\n",
    "\n",
    "# Function to calculate evaluation metrics for a given classifier\n",
    "def calculate_metrics(classifier_name, X_test, y_test, new_threshold=0.4):\n",
    "    classifier = build_classifier(classifier_name)\n",
    "    pipe_classifier = pipeline.Pipeline(steps=[(\"Scaler\", StandardScaler()), (\"Model\", classifier)])\n",
    "    pipe_classifier.fit(X_train, y_train)\n",
    "\n",
    "    y_score = pipe_classifier.predict_proba(X_test)[:, 1]\n",
    "    y_pred = (y_score > new_threshold).astype(int)\n",
    "\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    TP = cm[1, 1]  # true positive\n",
    "    TN = cm[0, 0]  # true negatives\n",
    "    FP = cm[0, 1]  # false positives\n",
    "    FN = cm[1, 0]  # false negatives\n",
    "    Specificity = TN / (TN + FP)\n",
    "    Sensitivity = TP / (FN + TP)\n",
    "\n",
    "    AUC = roc_auc_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    ACC = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return AUC, Sensitivity, Specificity, f1, ACC\n",
    "\n",
    "# Function to plot adjacency subnetwork\n",
    "def plot_adjacency_subnetwork(edges, network_order, mode, cmap, idx_to_label):\n",
    "    network_colors = {region: \"#232324\" for region in network_order}\n",
    "    plt.figure(figsize=(11, 11))\n",
    "    plot_chord(\n",
    "        idx_to_label,\n",
    "        edges,\n",
    "        network_order=network_order,\n",
    "        linewidths=7,\n",
    "        alphas=0.9,\n",
    "        do_ROI_circles=True,\n",
    "        do_ROI_circles_specific=True,\n",
    "        ROI_circle_radius=0.02,\n",
    "        cmap=cmap,\n",
    "        network_colors=network_colors,\n",
    "        mode=mode\n",
    "    )\n",
    "    plt.show()\n",
    "\n",
    "# ... (data loading and preprocessing)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    AUC_BRF, Sensitivity_BRF, Specificity_BRF, AucPred_BRF, f1_BRF, ACC_BRF = [], [], [], [], [], []\n",
    "    AUC_EEC, Sensitivity_EEC, Specificity_EEC, AucPred_EEC, f1_EEC, ACC_EEC = [], [], [], [], [], []\n",
    "    AUCs, Specificities, Sensitivities, f1s, ACCs = [], [], [], [], []\n",
    "\n",
    "    for _ in tqdm(range(50)):\n",
    "        X_train_normalized, X_test_normalized = normalize_data(X_train, X_test)\n",
    "\n",
    "        # EEC\n",
    "        AUC_eec, Sensitivity_eec, Spcifity_eec, f1_eec, ACC_eec = calculate_metrics(\"EEC\", X_test_normalized, y_test)\n",
    "        AUC_EEC.append(AUC_eec)\n",
    "        Sensitivity_EEC.append(Sensitivity_eec)\n",
    "        Specificity_EEC.append(Spcifity_eec)\n",
    "        f1_EEC.append(f1_eec)\n",
    "        ACC_EEC.append(ACC_eec)\n",
    "\n",
    "        # BRF\n",
    "        AUC_brf, Sensitivity_brf, Spcifity_brf, f1_brf, ACC_brf = calculate_metrics(\"BRF\", X_test_normalized, y_test)\n",
    "        AUC_BRF.append(AUC_brf)\n",
    "        Sensitivity_BRF.append(Sensitivity_brf)\n",
    "        Specificity_BRF.append(Spcifity_brf)\n",
    "        f1_BRF.append(f1_brf)\n",
    "        ACC_BRF.append(ACC_brf)\n",
    "\n",
    "        # XGB\n",
    "        AUC_xgb, Sensitivity_xgb, Specificity_xgb, f1_xgb, ACC_xgb = calculate_metrics(\"XGB\", X_test_normalized, y_test)\n",
    "        AUCs.append(AUC_xgb)\n",
    "        Sensitivities.append(Sensitivity_xgb)\n",
    "        Specificities.append(Specificity_xgb)\n",
    "        f1s.append(f1_xgb)\n",
    "        ACCs.append(ACC_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.45567272727272723\n",
      "0.21454545454545457\n",
      "0.6968000000000001\n",
      "0.22430585700325906\n",
      "0.5494444444444446\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(AUC_BRF))\n",
    "print(np.mean(Sensitivity_BRF))\n",
    "print(np.mean(spcifity_BRF))\n",
    "print(np.mean(f1_BRF))\n",
    "print(np.mean(ACC_BRF))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.44047272727272735\n",
      "0.29454545454545455\n",
      "0.5864000000000001\n",
      "0.26111857192726756\n",
      "0.4972222222222223\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(AUC_EEC))\n",
    "print(np.mean(Sensitivity_EEC))\n",
    "print(np.mean(spcifity_EEC))\n",
    "print(np.mean(f1_EEC))\n",
    "print(np.mean(ACC_EEC))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4763636363636364\n",
      "0.68\n",
      "0.2727272727272727\n",
      "0.2727272727272727\n",
      "0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(AUCs))\n",
    "print(np.mean(Specificities))\n",
    "print(np.mean(Sensitivities))\n",
    "print(np.mean(f1s))\n",
    "print(np.mean(ACCs))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "interpreter": {
   "hash": "bbeef1641d091e35d93df74aa93d1a5e7a7fb87503981bf92f3d78628af6c7b5"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
